{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "685b7ac9",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a33b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ced6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper:\n",
    "\n",
    "    def __init__(self, pullQuantity = 10000):\n",
    "        self.session = requests.Session()\n",
    "        self.startTime = time.time()\n",
    "        self.pullQuantity = pullQuantity\n",
    "        self.staticURL = 'https://www.wine.com'\n",
    "        self.siteMapDirectory = '../../data/wine-com/'\n",
    "        self.filePath = '../../data/wine-com/raw/{}.txt'.format(self.startTime)\n",
    "        self.headerData = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'}\n",
    "\n",
    "       #determine if sitemap exists, initialize if not\n",
    "        try:\n",
    "            with open(self.siteMapDirectory + '/site-map.json', 'r') as fileObj:\n",
    "                self.siteMap = json.load(fileObj)\n",
    "        except:\n",
    "            self.siteMap = {}\n",
    "        \n",
    "        #generate session file - validated\n",
    "        with open(self.filePath,'w') as fileObj:\n",
    "            fileObj.write('product_url|product_name|product_variety|product_origin|product_family|user_avg_rating|user_rating_count|product_description|product_reviews\\n')  \n",
    "        fileObj.close()\n",
    "            \n",
    "    def scrape(self):\n",
    "        #determine landing page map exists\n",
    "        if len(self.siteMap) == 0:\n",
    "            self.scrapeLandingPage()\n",
    "            self.parseLandingPage()\n",
    "        #iterate through wine varieties\n",
    "        sleep(2)\n",
    "        for key, value in self.siteMap['landingPageLinks'].items():\n",
    "            self.searchVarietal = key\n",
    "            self.searchURL = value\n",
    "            self.scrapeParseResultsPage()\n",
    "            #write sitemap to JSON file\n",
    "            with open(self.siteMapDirectory + '/site-map.json', 'w') as fileObj:\n",
    "                json.dump(self.siteMap, fileObj)\n",
    "            fileObj.close()\n",
    "\n",
    "    # validated\n",
    "    def scrapeLandingPage(self):\n",
    "        landingPageResponse = self.session.get(self.staticURL, headers = self.headerData)\n",
    "        self.landingPageSoup = BeautifulSoup(landingPageResponse.content, \"html.parser\")\n",
    "    \n",
    "    #validated\n",
    "    def parseLandingPage(self):\n",
    "        self.siteMap['landingPageLinks'] = dict()\n",
    "        landingPageVarietalsLevel0 = self.landingPageSoup.find('section', attrs = {'class': 'mainNav_section mainNav_section-varietal mainNavList_item-level0'})\n",
    "        for row in landingPageVarietalsLevel0.find_all('li', attrs = {'class': 'mainNavList_item mainNavList_item-level2'}):\n",
    "            a_tag = row.find('a', attrs = {'class': 'mainNavList_itemLink'})\n",
    "            self.varietalName = a_tag.text\n",
    "            self.varietalLink = a_tag.get('href')\n",
    "            self.siteMap['landingPageLinks'][self.varietalName] = self.staticURL + self.varietalLink\n",
    "        #for some reason boxed sets and glassware links are present in varietals tab\n",
    "        del self.siteMap['landingPageLinks']['Wine Tasting Sets']\n",
    "        del self.siteMap['landingPageLinks']['Glassware & Accessories']\n",
    "    \n",
    "    def scrapeParseResultsPage(self):\n",
    "        if self.searchVarietal not in self.siteMap:\n",
    "            self.siteMap[self.searchVarietal] = dict()\n",
    "        \n",
    "        self.pullCount = 0\n",
    "        while self.pullCount < self.pullQuantity and self.searchURL is not None:\n",
    "            print(self.searchURL)\n",
    "            resultsPageResponse = self.session.get(self.searchURL, headers = self.headerData)\n",
    "            self.resultsPageSoup = BeautifulSoup(resultsPageResponse.content, \"html.parser\")\n",
    "            resultsContainer = self.resultsPageSoup.find('ul', attrs = {'class':'listGridLayout_list'})\n",
    "            for row in resultsContainer.find_all('div', attrs = {'class': 'listGridItemInfo'}):\n",
    "                productShortLink = row.a['href']\n",
    "                self.productURL = self.staticURL + productShortLink\n",
    "                if self.productURL not in self.siteMap[self.searchVarietal]:\n",
    "                    self.scrapeProductPage()\n",
    "                    self.parseProductPage()\n",
    "                else:\n",
    "                    pass\n",
    "            if self.pullCount < self.pullQuantity:\n",
    "                try:\n",
    "                    paginationContainer = self.resultsPageSoup.find('div', attrs = {'class':'nextPagePagination'})\n",
    "                    self.searchURL = paginationContainer.a['href']\n",
    "                except Exception:\n",
    "                    self.searchURL = None\n",
    "            \n",
    "    #validated\n",
    "    def scrapeProductPage(self):\n",
    "        if self.productURL not in self.siteMap[self.searchVarietal]:\n",
    "            self.siteMap[self.searchVarietal][self.productURL] = dict()\n",
    "        \n",
    "        try:\n",
    "            productPageResponse = self.session.get(self.productURL, headers = self.headerData)\n",
    "            self.productPageSoup = BeautifulSoup(productPageResponse.content, \"html.parser\")\n",
    "            \n",
    "            self.siteMap[self.searchVarietal][self.productURL]['scrapeStatus'] = 'success'\n",
    "        except Exception:\n",
    "            self.siteMap[self.searchVarietal][self.productURL]['scrapeStatus'] = 'fail'\n",
    "            \n",
    "    #validated\n",
    "    def parseProductPage(self):\n",
    "        try:\n",
    "            #generate dictionary for parsed fields\n",
    "            self.prodData = dict()\n",
    "            \n",
    "            #product info\n",
    "            prodInfo = self.productPageSoup.find('div', attrs = {'class':'pipInfo'})\n",
    "            self.prodData['Product_Name'] = prodInfo.find('h1', attrs = {'class':'pipName'}).text\n",
    "            self.prodData['Product_Variety'] = prodInfo.find('span', attrs = {'class':'prodItemInfo_varietal'}).text\n",
    "            self.prodData['Product_Origin'] = prodInfo.find('span', attrs = {'class':'prodItemInfo_originText'}).text\n",
    "            \n",
    "            #product attributes\n",
    "            self.prodData['Product_Family'] = self.searchVarietal\n",
    "            \n",
    "            try:\n",
    "                #average user product ratings\n",
    "                self.prodData['User_Avg_Rating'] = self.productPageSoup.find('span', attrs = {'class':'averageRating_average'}).text\n",
    "            except Exception:\n",
    "                self.prodData['User_Avg_Rating'] = 'nan'\n",
    "                \n",
    "            try:\n",
    "                #product ratings count\n",
    "                self.prodData['User_Rating_Count'] = self.productPageSoup.find('span', attrs = {'class':'averageRating_number'}).text\n",
    "            except Exception:\n",
    "                self.prodData['User_Rating_Count'] = 'nan'\n",
    "                \n",
    "            try:\n",
    "                #winemaker notes\n",
    "                prodNotes = self.productPageSoup.find('div', attrs = {'class':'pipWineNotes_copy viewMoreModule js-expanded'})\n",
    "                wineMakerNotes = prodNotes.find('div', attrs = {'class': 'viewMoreModule_text'}).text\n",
    "                wineMakerNotes = wineMakerNotes.replace('\\n', ' ')\n",
    "                wineMakerNotes = unicodedata.normalize('NFKD', wineMakerNotes)\n",
    "                self.prodData['Winemaker_Description'] = wineMakerNotes\n",
    "            except Exception:\n",
    "                self.prodData['Winemaker_Description'] = 'nan'\n",
    "            \n",
    "            try:\n",
    "                #professional reviews\n",
    "                prodProfessionalReviews = self.productPageSoup.find('div', attrs = {'class': 'viewMoreModule_text viewMoreModule-reviews'})\n",
    "                self.prodData['Critical_Reviews'] = []\n",
    "                for row in prodProfessionalReviews.find_all('div', attrs = {'class': 'pipProfessionalReviews_list'}):\n",
    "                    reviewer_name = row.find('div', attrs = {'class': 'pipProfessionalReviews_authorName'}).text\n",
    "                    reviewer_rating = row.find('span', attrs = {'class': 'wineRatings_rating'}).text\n",
    "                    reviewer_text = row.find('div', attrs = {'class': 'pipSecContent_copy'}).text\n",
    "                    reviewer_text = reviewer_text.replace('\\n', ' ')\n",
    "                    reviewer_text = unicodedata.normalize('NFKD', reviewer_text)                             \n",
    "                    self.prodData['Critical_Reviews'].append(f'({reviewer_name}; {reviewer_rating}; {reviewer_text})')\n",
    "            except Exception:\n",
    "                print('review parse failed')\n",
    "                self.prodData['Critical_Reviews'] = 'nan'\n",
    "\n",
    "            #write data to disk\n",
    "            self.writeProductData()\n",
    "            self.siteMap[self.searchVarietal][self.productURL]['parseStatus'] = 'success'\n",
    "        except Exception:\n",
    "            self.siteMap[self.searchVarietal][self.productURL]['parseStatus'] = 'fail'\n",
    "            print('{} parse failed'.format(self.productURL))\n",
    "\n",
    "    #validated\n",
    "    def writeProductData(self):\n",
    "        try:\n",
    "            with open(self.filePath, 'a') as file:\n",
    "                file.write('{}|{}|{}|{}|{}|{}|{}|{}|{}\\n'.format(self.productURL,\n",
    "                                                                 self.prodData['Product_Name'],\n",
    "                                                                 self.prodData['Product_Variety'],\n",
    "                                                                 self.prodData['Product_Origin'],\n",
    "                                                                 self.prodData['Product_Family'],\n",
    "                                                                 self.prodData['User_Avg_Rating'],\n",
    "                                                                 self.prodData['User_Rating_Count'],\n",
    "                                                                 self.prodData['Winemaker_Description'],\n",
    "                                                                 self.prodData['Critical_Reviews']))\n",
    "            file.close()\n",
    "            self.pullCount += 1\n",
    "            self.siteMap[self.searchVarietal][self.productURL]['writeStatus'] = 'success'\n",
    "        except Exception:\n",
    "            self.siteMap[self.searchVarietal][self.productURL]['writeStatus'] = 'fail'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_com_scraper = Scraper()\n",
    "wine_com_scraper.scrape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
